# EasyTune-LLM 大模型微调平台功能介绍

## 📋 目录
- [平台概述](#平台概述)
- [核心功能](#核心功能)
- [技术架构](#技术架构)
- [使用场景](#使用场景)
- [快速开始](#快速开始)

---

## 🎯 平台概述

**EasyTune-LLM** 是一个专业的大语言模型微调平台，旨在简化 LLM 微调流程，让开发者和研究人员能够轻松地：
- 管理训练数据集
- 选择和配置基座模型
- 创建和监控训练任务
- 部署和测试微调后的模型

### 平台特色
- 🚀 **零代码操作**：通过友好的 Web 界面完成全流程
- 🔧 **灵活配置**：支持 LoRA、全量微调等多种训练方式
- 📊 **实时监控**：训练进度、日志实时查看
- 🎨 **现代化 UI**：基于 Ant Design 的美观界面
- ⚡ **高性能**：支持 GPU/MPS 加速训练

---

## 🎪 核心功能

### 1️⃣ 数据集管理

#### 功能列表
- **文件上传**
  - 支持 JSON、JSONL、CSV、TXT 格式
  - 自动解析数据结构
  - 实时显示样本数量
  - 文件大小验证
  
- **数据预览**
  - 表格化展示数据内容
  - 支持查看前 N 条样本
  - 显示字段结构和类型
  
- **数据集列表**
  - 展示所有已上传数据集
  - 显示样本数量、格式、创建时间
  - 支持搜索和筛选
  
- **数据集删除**
  - 一键删除不需要的数据集
  - 自动清理关联文件

#### 使用场景
```
场景：微调一个客服机器人
1. 准备客服对话数据（JSON格式）
2. 通过 Web 界面上传数据集
3. 系统自动解析并统计样本数
4. 预览数据确认格式正确
```

#### 支持的数据格式示例
```json
// JSON 格式（多轮对话）
[
  {
    "instruction": "如何退款？",
    "input": "",
    "output": "您可以在订单详情页点击申请退款..."
  }
]

// JSONL 格式（单样本一行）
{"question": "产品质量如何？", "answer": "我们的产品经过严格质检..."}
{"question": "发货时间？", "answer": "通常在24小时内发货..."}
```

---

### 2️⃣ 模型管理

#### 功能列表
- **基座模型库**
  - 预置热门开源模型（Qwen、LLaMA、ChatGLM 等）
  - 一键选择添加
  - 自动同步模型信息
  
- **自定义模型**
  - 支持 HuggingFace 模型路径
  - 支持 ModelScope 模型路径
  - 支持本地模型路径
  
- **模型服务管理**
  - 自动下载模型文件
  - 启动本地推理服务
  - 配置远程 API 访问
  
- **模型列表**
  - 展示所有可用模型
  - 显示模型类型、状态、路径
  - 支持删除不需要的模型

#### 预置模型示例
| 模型名称 | 参数规模 | 适用场景 | 特点 |
|---------|---------|---------|------|
| Qwen2-7B | 7B | 通用对话 | 中文能力强 |
| Qwen2-72B | 72B | 复杂推理 | 性能优异 |
| LLaMA-3-8B | 8B | 英文对话 | 开源主流 |
| ChatGLM3-6B | 6B | 中文对话 | 清华开源 |
| Baichuan2-13B | 13B | 中文通用 | 百川智能 |

#### 模型下载加速
```bash
# 支持 HuggingFace 镜像
export HF_ENDPOINT=https://hf-mirror.com

# 支持 ModelScope 国内源
pip install modelscope
```

---

### 3️⃣ 训练任务管理

#### 功能列表
- **任务创建**
  - 多步骤表单引导
  - 智能参数推荐
  - 实时参数验证
  
- **训练配置**
  - 选择基座模型
  - 选择训练数据集
  - 配置超参数（学习率、批次大小、训练轮数等）
  - 选择训练方式（LoRA、全量微调）
  
- **任务监控**
  - 实时查看训练状态
  - 进度条显示训练进度
  - 训练指标可视化
  
- **任务控制**
  - 停止正在运行的任务
  - 删除已完成的任务
  - 重新启动失败的任务
  
- **任务列表**
  - 展示所有训练任务
  - 状态筛选（运行中、已完成、失败等）
  - 快速操作按钮

#### 训练状态
```
PENDING    → 等待开始
PREPARING  → 准备环境
RUNNING    → 训练中
COMPLETED  → 已完成
FAILED     → 失败
STOPPED    → 已停止
```

#### 任务创建流程
```
步骤 1: 基本信息
  ├─ 任务名称
  ├─ 任务描述
  └─ 训练意图（问答、对话、分类等）

步骤 2: 模型和数据
  ├─ 选择基座模型
  ├─ 选择训练数据集
  └─ 验证数据兼容性

步骤 3: 训练配置
  ├─ 任务复杂度（简单、中等、复杂）
  ├─ 训练方式（LoRA、全量微调）
  ├─ 学习率、批次大小、训练轮数
  └─ 输出模型名称

步骤 4: 确认提交
  ├─ 预览所有配置
  ├─ 估算训练时间
  └─ 提交任务
```

---

### 4️⃣ 训练日志监控

#### 功能列表
- **实时日志查看**
  - 流式显示训练日志
  - 自动滚动到最新内容
  - 支持暂停/继续
  
- **日志下载**
  - 导出完整训练日志
  - 支持离线分析
  
- **日志搜索**
  - 关键词高亮
  - 快速定位错误信息
  
- **日志过滤**
  - 按级别过滤（INFO、WARNING、ERROR）
  - 按时间段筛选

#### 日志内容示例
```
INFO: ✅ 检测到 Apple Silicon GPU (MPS)
INFO: 🔧 自动选择计算设备: MPS
INFO: 📦 加载模型: Qwen/Qwen2-7B
INFO: 📚 加载数据集: 992 条样本
INFO: 🚀 开始训练...
INFO: Epoch 1/3 - Loss: 2.345
INFO: Epoch 2/3 - Loss: 1.234
INFO: Epoch 3/3 - Loss: 0.876
INFO: ✅ 训练完成！
INFO: 💾 保存模型到: ./lora_adapters/qwen2-7b-customer_service
```

---

### 5️⃣ 仪表盘

#### 功能列表
- **统计概览**
  - 数据集总数
  - 模型总数
  - 训练任务总数
  - 运行中任务数
  
- **快捷操作**
  - 快速创建任务
  - 查看最新任务
  - 跳转到各功能模块
  
- **系统状态**
  - 磁盘使用情况
  - GPU/CPU 使用率
  - 内存占用

#### 仪表盘布局
```
┌─────────────────────────────────────┐
│  欢迎使用 EasyTune-LLM 平台         │
├─────────────────────────────────────┤
│  📊 数据集: 5 个                    │
│  🤖 模型: 3 个                      │
│  📝 任务: 12 个 (2 个运行中)        │
├─────────────────────────────────────┤
│  最近任务                            │
│  ├─ 客服机器人微调 (运行中)         │
│  ├─ 问答模型训练 (已完成)           │
│  └─ 分类任务 (失败)                 │
├─────────────────────────────────────┤
│  快捷操作                            │
│  [创建任务] [上传数据] [添加模型]   │
└─────────────────────────────────────┘
```

---

## 🏗️ 技术架构

### 前端技术栈
- **框架**: React 18 + TypeScript
- **UI 库**: Ant Design 5.x
- **路由**: React Router v6
- **状态管理**: React Hooks
- **HTTP 客户端**: Axios
- **构建工具**: Vite

### 后端技术栈
- **Web 框架**: FastAPI
- **数据库**: PostgreSQL 14+
- **ORM**: SQLAlchemy 2.0
- **异步**: asyncio + asyncpg
- **进程管理**: psutil
- **任务调度**: 自定义训练引擎

### 训练引擎
- **深度学习框架**: PyTorch 2.0+
- **Transformers**: HuggingFace Transformers
- **高效微调**: PEFT (LoRA, QLoRA)
- **模型服务**: vLLM (可选)
- **硬件支持**: CUDA, MPS, CPU

### 系统架构图
```
┌──────────────────────────────────────────────┐
│              前端 (React + Ant Design)         │
│  ┌──────┐  ┌──────┐  ┌──────┐  ┌──────┐     │
│  │仪表盘│  │数据集│  │ 模型 │  │ 任务 │     │
│  └──────┘  └──────┘  └──────┘  └──────┘     │
└──────────────────┬───────────────────────────┘
                   │ HTTP/REST API
┌──────────────────▼───────────────────────────┐
│          API Gateway (FastAPI)                │
│  ┌─────────────────────────────────────┐     │
│  │  Routers (datasets, models, tasks)  │     │
│  └─────────────────────────────────────┘     │
└──────────────────┬───────────────────────────┘
                   │
┌──────────────────▼───────────────────────────┐
│              业务逻辑层                        │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │数据集管理│  │模型服务  │  │任务调度  │   │
│  └──────────┘  └──────────┘  └──────────┘   │
└──────────────────┬───────────────────────────┘
                   │
┌──────────────────▼───────────────────────────┐
│            数据持久层                          │
│  ┌─────────────┐      ┌─────────────┐       │
│  │  PostgreSQL │      │ 文件系统    │       │
│  │  (元数据)   │      │ (模型/数据) │       │
│  └─────────────┘      └─────────────┘       │
└──────────────────────────────────────────────┘
                   │
┌──────────────────▼───────────────────────────┐
│              训练引擎层                        │
│  ┌──────────────────────────────────────┐   │
│  │  PyTorch + Transformers + PEFT       │   │
│  │  (独立进程，GPU/MPS 加速)             │   │
│  └──────────────────────────────────────┘   │
└──────────────────────────────────────────────┘
```

---

## 🎬 使用场景

### 场景 1: 客服机器人微调
```
需求: 为公司定制一个专业的客服机器人

步骤:
1. 收集公司客服对话历史 (问题-答案对)
2. 整理成 JSON 格式上传到平台
3. 选择 Qwen2-7B 作为基座模型
4. 创建训练任务，配置 LoRA 微调
5. 训练完成后部署使用

预期效果:
- 回答准确率提升 30%+
- 响应更贴合公司业务
- 训练时间: 2-4 小时 (取决于数据量)
```

### 场景 2: 专业领域问答系统
```
需求: 构建医疗领域的智能问答系统

步骤:
1. 准备医疗知识库和FAQ数据
2. 上传到平台并预览数据质量
3. 选择 ChatGLM3-6B (中文医疗友好)
4. 配置较大的训练轮数 (5-10 epochs)
5. 监控训练指标，确保收敛

预期效果:
- 专业术语理解准确
- 回答符合医疗规范
- 适合医院咨询场景
```

### 场景 3: 文本分类任务
```
需求: 自动分类用户反馈（正面/负面/中性）

步骤:
1. 准备标注好的反馈数据
2. 上传数据集（包含文本和标签）
3. 选择轻量级模型 (Qwen2-1.5B)
4. 配置分类任务参数
5. 快速训练并评估效果

预期效果:
- 分类准确率 85%+
- 推理速度快（毫秒级）
- 适合实时场景
```

### 场景 4: 多语言翻译模型
```
需求: 微调一个中英翻译模型

步骤:
1. 准备平行语料（中英对照）
2. 上传训练数据和验证数据
3. 选择 LLaMA-3-8B 多语言版本
4. 配置 Seq2Seq 训练参数
5. 评估 BLEU 分数

预期效果:
- 翻译质量接近专业水平
- 保留上下文信息
- 适合文档翻译
```

---

## 🚀 快速开始

### 环境要求
```
硬件:
- CPU: 4 核心及以上
- 内存: 16GB 及以上
- 显卡: NVIDIA GPU (8GB+ 显存) 或 Apple Silicon (M1/M2/M3)
- 磁盘: 50GB 可用空间

软件:
- Python 3.9+
- Node.js 16+
- PostgreSQL 14+
- CUDA 11.8+ (NVIDIA GPU) 或 macOS 13+ (Apple Silicon)
```

### 安装步骤

#### 1. 克隆项目
```bash
git clone https://github.com/your-repo/EasyTune-LLM.git
cd EasyTune-LLM
```

#### 2. 安装后端依赖
```bash
# 创建虚拟环境
conda create -n easytune python=3.10
conda activate easytune

# 安装依赖
pip install -r backend/requirements.txt
pip install -r training-engine/requirements.txt
```

#### 3. 配置数据库
```bash
# 创建数据库
createdb easytune_db

# 运行迁移
cd backend
alembic upgrade head
```

#### 4. 启动后端服务
```bash
# 方式1: 使用脚本
./start_backend_fixed.sh

# 方式2: 手动启动
cd backend/api-gateway
export PYTHONPATH="/path/to/EasyTune-LLM:$PYTHONPATH"
uvicorn main:app --reload --port 8000
```

#### 5. 安装前端依赖
```bash
cd frontend
npm install
```

#### 6. 启动前端服务
```bash
npm run dev
# 访问 http://localhost:5173
```

### 首次使用

#### 第一步: 创建账号并登录
```bash
# 访问登录页面
http://localhost:5173/login

# 使用测试账号
用户名: admin
密码: admin123
```

#### 第二步: 上传第一个数据集
```bash
1. 进入"数据集管理"页面
2. 点击"上传数据集"
3. 选择文件并填写信息
4. 上传成功后查看预览
```

#### 第三步: 添加基座模型
```bash
1. 进入"模型管理"页面
2. 点击"添加模型"
3. 选择预置模型或输入自定义路径
4. 等待模型信息加载完成
```

#### 第四步: 创建训练任务
```bash
1. 进入"训练任务"页面
2. 点击"创建新任务"
3. 按步骤填写配置信息
4. 提交任务并等待训练开始
```

#### 第五步: 监控训练过程
```bash
1. 在任务列表中点击任务名称
2. 查看训练详情和实时日志
3. 等待训练完成
4. 下载微调后的模型
```

---

## 📚 详细文档

### 用户手册
- [数据集管理指南](./docs/DATASET_GUIDE.md)
- [模型服务指南](./docs/MODEL_SERVICE_GUIDE.md)
- [训练任务指南](./docs/TRAINING_GUIDE.md)
- [日志监控指南](./docs/LOGS_GUIDE.md)

### 开发文档
- [API 接口文档](./docs/API_DOCS.md)
- [数据库设计](./docs/DATABASE_SCHEMA.md)
- [训练引擎设计](./docs/TRAINING_ENGINE.md)
- [部署指南](./docs/DEPLOYMENT.md)

### 常见问题
- [FAQ - 常见问题解答](./docs/FAQ.md)
- [故障排查指南](./docs/TROUBLESHOOTING.md)
- [性能优化建议](./docs/PERFORMANCE.md)

---

## 🔧 高级功能

### 1. 分布式训练
```yaml
# 配置多 GPU 训练
training:
  distributed:
    enabled: true
    num_gpus: 4
    strategy: ddp  # DDP 或 FSDP
```

### 2. 自动超参数调优
```yaml
# 启用 Optuna 自动调参
hyperparameter_tuning:
  enabled: true
  trials: 20
  metric: validation_loss
```

### 3. 模型量化
```yaml
# 4-bit 量化训练
quantization:
  enabled: true
  bits: 4
  method: qlora
```

### 4. 梯度检查点
```yaml
# 节省显存
gradient_checkpointing:
  enabled: true
```

---

## 📊 性能基准

### 训练性能
| 模型规模 | 数据量 | 硬件 | 训练时间 | 显存占用 |
|---------|--------|------|---------|---------|
| 1.5B | 10K | RTX 3090 | 2h | 12GB |
| 7B | 10K | RTX 4090 | 4h | 20GB |
| 13B | 10K | A100 40GB | 6h | 35GB |
| 7B (LoRA) | 10K | RTX 3090 | 1.5h | 8GB |

### 推理性能
| 模型规模 | 硬件 | 吞吐量 (tokens/s) | 延迟 (ms) |
|---------|------|------------------|----------|
| 1.5B | RTX 3090 | 2000 | 50 |
| 7B | RTX 4090 | 800 | 120 |
| 13B | A100 | 500 | 200 |

---

## 🤝 贡献指南

欢迎贡献代码、报告问题或提出建议！

### 贡献流程
1. Fork 本项目
2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 提交 Pull Request

### 代码规范
- 前端: ESLint + Prettier
- 后端: Black + isort
- 提交信息: Conventional Commits

---

## 📄 许可证

本项目采用 MIT 许可证 - 详见 [LICENSE](LICENSE) 文件

---

## 🙏 致谢

- [HuggingFace Transformers](https://github.com/huggingface/transformers)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Ant Design](https://ant.design/)
- [PyTorch](https://pytorch.org/)
- [PEFT](https://github.com/huggingface/peft)

---

## 📞 联系我们

- 项目主页: [https://github.com/your-repo/EasyTune-LLM](https://github.com/your-repo/EasyTune-LLM)
- 问题反馈: [Issues](https://github.com/your-repo/EasyTune-LLM/issues)
- 邮箱: support@easytune-llm.com
- 微信群: 扫码加入（二维码）

---

<div align="center">

**⭐ 如果觉得有帮助，请给我们一个 Star！⭐**

Made with ❤️ by EasyTune-LLM Team

</div>

